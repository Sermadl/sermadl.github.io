---
title: "ìƒì„±í˜• AI ë¯¸ë‹ˆ í”„ë¡œì íŠ¸(3): Open AI ì‹¤ì‹œê°„ ì‘ë‹µ êµ¬í˜„í•˜ê¸° (feat. SSE)"
categories: [Fast API]
tags: [ML, Fast API, SSE, Open AI API, SKALA, SKALA1ê¸°, SK]
---

> Skala ê³¼ì •ì—ì„œ ìƒì„±í˜• AI ëŒ€í•´ ìƒˆë¡­ê²Œ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.<br>
> ìƒì„±í˜• AI ìˆ˜ì—… ì¤‘ ì§„í–‰í•˜ê²Œ ëœ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ êµ¬í˜„ ê³¼ì •ì„ ê¸°ìˆ í•©ë‹ˆë‹¤.

[ì²˜ìŒ ê¸€ ë³´ëŸ¬ê°€ê¸°](<https://sermadl.github.io/posts/ml-project(1)/>)

Open AIì˜ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ë‹¬í•˜ê³  ì‹¶ì–´ì„œ<br>
Fast APIì˜ StreaminResponseë¥¼ ì‚¬ìš©í•œ SSEë¥¼ í†µí•´ í•´ë‹¹ ê¸°ëŠ¥ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤!<br>

<hr>

## ì‹¤ì‹œê°„ ë²ˆì—­ ê¸°ëŠ¥ êµ¬í˜„í•˜ê¸°

### openai_router.py

```python
from typing import Union
from fastapi import APIRouter, Header, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from app.db.database import get_db

from app.services.openai_service import get_streaming_message_from_openai
from app.services.log_script_service import logger
from fastapi.responses import StreamingResponse
from app.dto.message_request import MessageRequest


router = APIRouter()

@router.post(
    "/translate",
    summary="Generate messages using OpenAI (streaming)",
)
async def get_generated_messages_with_header(
    data: MessageRequest,
    x_script_id: Union[str, None] = Header(default=None),
    db: AsyncSession = Depends(get_db)
):
    """
    ## Open AIì— ë²ˆì—­ ìš”ì²­
    - Header: "x-script-id" í¬í•¨ë˜ì–´ì•¼ í•¨!
    - data: MessageRequest
        - lang: ì–¸ì–´ ì½”ë“œ (e.g., "en-US", "ko-KR")
        - message: ë²ˆì—­í•  ë©”ì‹œì§€
    """

    await logger(db, data, x_script_id)

    return StreamingResponse(
        get_streaming_message_from_openai(data),
        media_type="text/event-stream"
    )

    .
    .
    .
```

StreamingResponseë¥¼ ì‚¬ìš©í•´ì„œ SSEë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.<br>

<hr>

### openai_service.py

```python
import logging
import os
from fastapi import HTTPException
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_teddynote.messages import stream_response
from app.dto.message_request import MessageRequest

OPENAI_API_KEY=os.getenv("OPENAI_API_KEY")

model = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.5,
    openai_api_key=OPENAI_API_KEY,
    streaming=True
)

templete='{text}ì„ {lang}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ ëœ ë¬¸ì¥ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.'
prompt = PromptTemplate.from_template(templete)
output_parser = StrOutputParser()
chain = prompt | model | output_parser

async def get_streaming_message_from_openai(data: MessageRequest):
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        response = chain.astream({
            "text": data.message,
            "lang": data.lang
        })

        async for token in response:
            content = f"data: {token}\n\n"
            yield content
        yield "data: [DONE]\n\n"
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
        logging.error(f"Error occurred: {str(e)}")
        raise HTTPException(status_code=500, detail=f"OpenAI Error: {str(e)}")
```

ìˆ˜ì—… ì‹œê°„ì— ë°°ì› ë˜ `chain` ê³¼ `StrOutputParser` ì„ ì‚¬ìš©í•´ì„œ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì‡ê³ , ì‘ë‹µì„ ì˜ˆì˜ê²Œ(ì›í•˜ëŠ” ì •ë³´ë§Œ) ë°›ì„ ìˆ˜ ìˆê²Œ ì„¤ì •í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.<br>

`streaming` ì˜µì…˜ì„ Trueë¡œ ì„¤ì •í•´ì„œ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í•˜ë„ë¡ í•´ì£¼ê³  `astream` ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ì™”ìŠµë‹ˆë‹¤.<br>

> `stream` ì€ ë™ê¸° ë°©ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì£¼ëŠ” í•¨ìˆ˜ì´ê³ , `astream` ì´ ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì£¼ëŠ” í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— `astream` ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤!

`aysnc for` ì„ ì‚¬ìš©í•´ì„œ ì‘ë‹µì´ ì˜¬ ë•Œë§ˆë‹¤ SSEë¡œ ê²°ê³¼ë¥¼ ì „ì†¡í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.<br>

<hr>

## ë§ˆì¹˜ë©°

ì´ì „ STTì— ë¹„í•´ êµ‰ì¥íˆ ì‹±ê²ê²Œ(?) ëë‚¬ì§€ë§Œ,,<br>
ì˜µì…˜ê³¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `ChatOpenAI` ê°ì²´ë¥¼ ëœ¯ì–´ë´¤ìŠµë‹ˆë‹¤,,<br>

ìª¼ê¸ˆ ì˜¤ë˜ê±¸ë ¸ì–´ìš©,,<br>

ì°¸ê³ í•˜ì‹œê³  í–‰ë³µí•œ ì½”ë”© ìƒí™œ í•˜ì„¸ìš¥ ğŸ˜€

<hr>
<br>

> ì°¸ê³  ìë£Œ

[í•˜ë‚˜](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)
